%% Machine Learning Online Class - Exercise 2: Logistic Regression
%
%  Instructions
%  ------------
% 
%  This file contains code that helps you get started on the logistic
%  regression exercise. You will need to complete the following functions 
%  in this exericse:
%
%     sigmoid.m
%     costFunction.m
%     predict.m
%     costFunctionReg.m
%
%  For this exercise, you will not need to change any code in this file,
%  or any other files other than those mentioned above.
%

%% Initialization
clear ; close all; clc

true_theta = [0.5;0.3]; %0.5 + 0.3*x
n = 1000;

%%Generate Data and label
xx = -10 + 20*rand(n,1);
x = [ones(n,1) xx];
y = zeros(n,1);
y_filter = zeros(n,1);


for i = 1 : n
    threshold = 1/(1+exp(1)^(-x(i,:)*true_theta));
    coin = rand(1,1);
    if threshold*0.8 > coin
        y(i) = 1;
    else
        y(i) = 0;
    end
    
    if threshold > 0.5
        y_filter(i) = 1;
    else
        y_filter(i) = 0;
    end
end


initial_theta = zeros(2,1);

%  Run fminunc to obtain the optimal theta
%  This function will return theta and the cost 
options = optimset('GradObj', 'on', 'MaxIter', 200);

[theta_filter, cost_filter] = ...
	fminunc(@(t)(costFunction(t, x, y_filter)), initial_theta, options)

[theta, cost] = ...
	fminunc(@(t)(costFunction(t, x, y)), initial_theta, options)

%%Plot the logistic function
test_X = [-10:0.01:10];
for i = 1:2001
    prob(i) = 1/(1+exp(1)^(-[1 test_X(i)]*true_theta));
end
plot(test_X,prob,'b');

hold on;
for i = 1:2001
    prob(i) = 1/(1+exp(1)^(-[1 test_X(i)]*theta_filter));
end
plot(test_X,prob,'m');

hold on;
for i = 1:2001
    prob(i) = 1/(1+exp(1)^(-[1 test_X(i)]*theta));
end
plot(test_X,prob,'r');

%%Output accuracy
p = predict(theta, x);
fprintf('Train Accuracy: %f\n', mean(double(p == y)) * 100);

p = predict(theta_filter, x);
fprintf('Train Accuracy: %f\n', mean(double(p == y)) * 100);
